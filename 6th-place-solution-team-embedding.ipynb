{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddec2f99",
   "metadata": {
    "papermill": {
     "duration": 0.012106,
     "end_time": "2022-04-05T13:07:21.348049",
     "exception": false,
     "start_time": "2022-04-05T13:07:21.335943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train Team Embedding for one epoch\n",
    "\n",
    "## Warning\n",
    "1. This method only got 472th/659 in [March Machine Learning Mania 2022 - Women's](https://www.kaggle.com/competitions/womens-march-mania-2022).\n",
    "2. The config of the following code isn't the config of my final submission.\n",
    "\n",
    "\n",
    "## Method\n",
    "\n",
    "### Model\n",
    "\n",
    "<img src=\"https://i.imgur.com/pY1b0mu.png\" alt=\"drawing\" width=\"350\" height=\"400\"/>\n",
    "\n",
    "- The goal of model:\n",
    "    - Given 2 team_id, predict the competition result\n",
    "- Input:\n",
    "    - **team_emb**: trained embedding, represent the embedding of given team_id, initialized with torch.nn.Embedding().\n",
    "- Output:\n",
    "    - **team1_win**: whether team1 win the game\n",
    "    - **team_info**: abbreviation of the competition detail result, contains ['Score','FGM','FGA','FGM3','FGA3','FTM','FTA','OR','DR','Ast','TO','Stl','Blk','PF'] \n",
    "\n",
    "\n",
    "### Data\n",
    "- **Training data**: \n",
    "    - RegularSeasonDetailedResults.csv\n",
    "- **Validation data**: \n",
    "    - NCAATourneyDetailedResults.csv\n",
    "\n",
    "### Preprocess\n",
    "1. Duplicate the data and make it symetrical to get rid of winner and loser.\n",
    "2. **Add feature** \"**is_win**\" which represent whether team1 win the game.\n",
    "2.  Apply **quantile transformation** to transform the **team_info** to normal distribution.\n",
    "\n",
    "### Training\n",
    "1. Train for one epoch along the timeline\n",
    "2. A minibatch is the data that has the same 'Season' and 'DayNum'.\n",
    "3. The team embeddings will be updated everyday.\n",
    "\n",
    "\n",
    "## Future work\n",
    "- Apply GNN to let a single game result of two teams affect other teams and enhance the ability of the model to apply the relationships between the teams.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd88b574",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T13:07:21.376894Z",
     "iopub.status.busy": "2022-04-05T13:07:21.375186Z",
     "iopub.status.idle": "2022-04-05T13:07:23.852509Z",
     "shell.execute_reply": "2022-04-05T13:07:23.853019Z",
     "shell.execute_reply.started": "2022-04-05T12:49:27.988069Z"
    },
    "papermill": {
     "duration": 2.49347,
     "end_time": "2022-04-05T13:07:23.853374",
     "exception": false,
     "start_time": "2022-04-05T13:07:21.359904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fae91c",
   "metadata": {
    "papermill": {
     "duration": 0.011647,
     "end_time": "2022-04-05T13:07:23.878953",
     "exception": false,
     "start_time": "2022-04-05T13:07:23.867306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebc1cd3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T13:07:23.903942Z",
     "iopub.status.busy": "2022-04-05T13:07:23.903319Z",
     "iopub.status.idle": "2022-04-05T13:07:23.941328Z",
     "shell.execute_reply": "2022-04-05T13:07:23.941816Z",
     "shell.execute_reply.started": "2022-04-05T12:49:28.341178Z"
    },
    "papermill": {
     "duration": 0.052194,
     "end_time": "2022-04-05T13:07:23.941985",
     "exception": false,
     "start_time": "2022-04-05T13:07:23.889791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Random Seed\n",
    "SEED = 2626\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# device\n",
    "DEVICE_IDS = \"\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = DEVICE_IDS\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device: {device}')\n",
    "\n",
    "# model\n",
    "TEAM_EMB_SIZE = 16\n",
    "MODEL_HIDDEN_SIZE = 32\n",
    "BATCH_SIZE = 2000\n",
    "\n",
    "# model training\n",
    "LEARNING_RATE = 1e-2\n",
    "## Loss weight of team1_win and detail_result predictions \n",
    "TEAM1_WIN_LOSS_WEIGHT = 0.7\n",
    "INFO_LOSS_WEIGHT = 1 - TEAM1_WIN_LOSS_WEIGHT\n",
    "## Loss weight of each columns of detail_result \n",
    "INFO_COLS_LOSS_WEIGHT = [5] + [0.1] * 13\n",
    "INFO_COLS_LOSS_WEIGHT = np.array(INFO_COLS_LOSS_WEIGHT) / np.sum(INFO_COLS_LOSS_WEIGHT)\n",
    "INFO_COLS_LOSS_WEIGHT = torch.tensor(INFO_COLS_LOSS_WEIGHT).to(device)\n",
    "INFO_COLS = ['Score','FGM','FGA','FGM3','FGA3','FTM','FTA','OR','DR','Ast','TO','Stl','Blk','PF']\n",
    "WIN_INFO_COLS = ['W'+col for col in INFO_COLS]\n",
    "LOSE_INFO_COLS = ['L'+col for col in INFO_COLS]\n",
    "\n",
    "# file\n",
    "GENDER = 'M'\n",
    "if GENDER == 'M':\n",
    "    DATA_DIR = f'../input/mens-march-mania-2022/MDataFiles_Stage2'\n",
    "else:\n",
    "    DATA_DIR = f'../input/womens-march-mania-2022/WDataFiles_Stage2'\n",
    "\n",
    "REGULAR_FILE = f'{GENDER}RegularSeasonDetailedResults.csv'\n",
    "NCAA_FILE = f'{GENDER}NCAATourneyDetailedResults.csv'\n",
    "SAMPLE_SUBMISSION_FILE = f'{GENDER}SampleSubmissionStage2.csv'\n",
    "\n",
    "# Season\n",
    "if GENDER == 'M':\n",
    "    SEASONS = list(range(2003, 2020)) + [2021, 2022]\n",
    "else:\n",
    "    SEASONS = list(range(2010, 2020)) + [2021, 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49553954",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T13:07:23.968326Z",
     "iopub.status.busy": "2022-04-05T13:07:23.967627Z",
     "iopub.status.idle": "2022-04-05T13:07:23.971417Z",
     "shell.execute_reply": "2022-04-05T13:07:23.971843Z",
     "shell.execute_reply.started": "2022-04-05T12:49:28.57491Z"
    },
    "papermill": {
     "duration": 0.018255,
     "end_time": "2022-04-05T13:07:23.972037",
     "exception": false,
     "start_time": "2022-04-05T13:07:23.953782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_df(file_name):\n",
    "    return pd.read_csv(f'{DATA_DIR}/{file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06028ef5",
   "metadata": {
    "papermill": {
     "duration": 0.011737,
     "end_time": "2022-04-05T13:07:23.995775",
     "exception": false,
     "start_time": "2022-04-05T13:07:23.984038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ee8b203",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T13:07:24.022187Z",
     "iopub.status.busy": "2022-04-05T13:07:24.021536Z",
     "iopub.status.idle": "2022-04-05T13:07:24.043797Z",
     "shell.execute_reply": "2022-04-05T13:07:24.043145Z",
     "shell.execute_reply.started": "2022-04-05T12:49:28.812961Z"
    },
    "papermill": {
     "duration": 0.036789,
     "end_time": "2022-04-05T13:07:24.043936",
     "exception": false,
     "start_time": "2022-04-05T13:07:24.007147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    def __init__(self, reg_df, nca_df, sub_df, device):\n",
    "        self.reg_df = reg_df.copy()\n",
    "        self.nca_df = nca_df.copy()\n",
    "        self.sub_df = sub_df.copy()\n",
    "        self.device = device\n",
    "        self.team_id_map = self.get_team_id_map()\n",
    "        self.num_team = len(self.team_id_map)\n",
    "        self.normalizer = self.get_normalizer()\n",
    "    \n",
    "    def get_test_data(self, season):\n",
    "        df = self.sub_df.copy()\n",
    "        df['Season'] = df['ID'].apply(lambda x: int(x.split('_')[0]))\n",
    "        df = df[df.Season == season]\n",
    "        team1_ids = df['ID'].apply(lambda x: int(x.split('_')[1])).astype(int).map(self.team_id_map)\n",
    "        team2_ids = df['ID'].apply(lambda x: int(x.split('_')[2])).astype(int).map(self.team_id_map)\n",
    "        team1_ids = torch.tensor(team1_ids.values).long().to(self.device)\n",
    "        team2_ids = torch.tensor(team2_ids.values).long().to(self.device)\n",
    "        return team1_ids, team2_ids\n",
    "    \n",
    "    def get_team_id_map(self):\n",
    "        df = self.reg_df\n",
    "        team_ids = set(list(df.WTeamID.unique()) + list(df.LTeamID.unique()))\n",
    "        return {team_id: i for i, team_id in enumerate(team_ids)}\n",
    "\n",
    "    def get_normalizer(self):\n",
    "        df = self.reg_df.copy()\n",
    "        qt = QuantileTransformer(random_state=SEED)\n",
    "        info_data = np.concatenate((df[WIN_INFO_COLS].values, df[LOSE_INFO_COLS].values), axis=0)\n",
    "        qt.fit(info_data)\n",
    "        return qt\n",
    "    \n",
    "    def process_df(self, _df, is_train=True):\n",
    "        df = _df.copy()\n",
    "        df.drop(columns=['WLoc','NumOT'], inplace=True)\n",
    "\n",
    "        # normalize\n",
    "        df[WIN_INFO_COLS] = self.normalizer.transform(df[WIN_INFO_COLS])\n",
    "        df[LOSE_INFO_COLS] = self.normalizer.transform(df[LOSE_INFO_COLS])\n",
    "\n",
    "        # map indices\n",
    "        df['WTeamID'] = df['WTeamID'].astype(int).map(self.team_id_map)\n",
    "        df['LTeamID'] = df['LTeamID'].astype(int).map(self.team_id_map)\n",
    "\n",
    "        ret = []\n",
    "        for _, group in df.groupby(['Season', 'DayNum']):\n",
    "            data1 = group[['WTeamID'] + WIN_INFO_COLS].values\n",
    "            data2 = group[['LTeamID'] + LOSE_INFO_COLS].values\n",
    "\n",
    "            if is_train:\n",
    "                # Duplicate the data and make it symetrical to get rid of winner and loser\n",
    "                _data1 = np.zeros((len(data1)*2, *data1.shape[1:]))\n",
    "                _data1[::2] = data1.copy()\n",
    "                _data1[1::2] = data2.copy()\n",
    "\n",
    "                _data2 = np.zeros((len(data2)*2, *data2.shape[1:]))\n",
    "                _data2[::2] = data2.copy()\n",
    "                _data2[1::2] = data1.copy()\n",
    "\n",
    "                data1 = _data1\n",
    "                data2 = _data2\n",
    "\n",
    "            tmp = {\n",
    "                'team1_ids': torch.tensor(data1[:, 0]).long().to(self.device),\n",
    "                'team2_ids': torch.tensor(data2[:, 0]).long().to(self.device),\n",
    "                'team1_data': torch.tensor(data1[:, 1:]).float().to(self.device),\n",
    "                'team2_data': torch.tensor(data2[:, 1:]).float().to(self.device),\n",
    "                'team1_win': torch.tensor(data1[:, 1] > data2[:, 1]).float().to(self.device)\n",
    "            }\n",
    "            ret.append(edict(tmp))\n",
    "        return ret\n",
    "    \n",
    "    def get_train_data(self, season=2016):\n",
    "        train_df = self.reg_df[self.reg_df.Season == season]\n",
    "        train_df = self.process_df(train_df)\n",
    "        if season < 2022:\n",
    "            valid_df = self.nca_df[self.nca_df.Season == season]\n",
    "            valid_df = self.process_df(valid_df, is_train=False)\n",
    "            test_data = None\n",
    "        else:\n",
    "            valid_df = None\n",
    "            test_data = self.get_test_data(season)\n",
    "        return train_df, valid_df, test_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a779b8",
   "metadata": {
    "papermill": {
     "duration": 0.010767,
     "end_time": "2022-04-05T13:07:24.066019",
     "exception": false,
     "start_time": "2022-04-05T13:07:24.055252",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MetricTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "850d5881",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T13:07:24.094289Z",
     "iopub.status.busy": "2022-04-05T13:07:24.093649Z",
     "iopub.status.idle": "2022-04-05T13:07:24.096799Z",
     "shell.execute_reply": "2022-04-05T13:07:24.096236Z",
     "shell.execute_reply.started": "2022-04-05T12:49:29.14096Z"
    },
    "papermill": {
     "duration": 0.019851,
     "end_time": "2022-04-05T13:07:24.096933",
     "exception": false,
     "start_time": "2022-04-05T13:07:24.077082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MetricTracker:\n",
    "    def __init__(self):\n",
    "        self.bce = 0\n",
    "        self.mse = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, count, bce, mse):\n",
    "        self.count += count\n",
    "        self.bce += bce * count\n",
    "        self.mse += mse * count\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"bce: {self.bce/self.count:.04f}, mse: {self.mse / self.count:.04f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16df437b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T13:07:24.130418Z",
     "iopub.status.busy": "2022-04-05T13:07:24.129723Z",
     "iopub.status.idle": "2022-04-05T13:07:24.131404Z",
     "shell.execute_reply": "2022-04-05T13:07:24.131848Z",
     "shell.execute_reply.started": "2022-04-05T12:49:29.473357Z"
    },
    "papermill": {
     "duration": 0.023775,
     "end_time": "2022-04-05T13:07:24.132015",
     "exception": false,
     "start_time": "2022-04-05T13:07:24.108240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IterativeModel(nn.Module):\n",
    "    def __init__(self, num_team, num_info=14, team_emb_size=32, model_emb_size=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.team_embs = nn.Embedding(num_team, team_emb_size)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.utils.weight_norm(nn.Linear(team_emb_size*2, model_emb_size*6)),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.BatchNorm1d(model_emb_size*6),\n",
    "            nn.utils.weight_norm(nn.Linear(model_emb_size*6, model_emb_size*4)),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.BatchNorm1d(model_emb_size*4),\n",
    "            nn.utils.weight_norm(nn.Linear(model_emb_size*4, model_emb_size*2)),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "        )\n",
    "        self.output_win = nn.Sequential(\n",
    "            nn.Linear(model_emb_size*2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.output_team1_info = nn.Linear(model_emb_size*2, num_info)\n",
    "        self.output_team2_info = nn.Linear(model_emb_size*2, num_info)\n",
    "    \n",
    "    def forward(self, team1_ids, team2_ids):\n",
    "        team1_embs = self.team_embs(team1_ids)\n",
    "        team2_embs = self.team_embs(team2_ids)\n",
    "\n",
    "        embs = torch.cat((team1_embs, team2_embs), dim=1)\n",
    "        embs = self.mlp(embs)\n",
    "\n",
    "        team1_win = self.output_win(embs).view(-1)\n",
    "        team1_info = self.output_team1_info(embs)\n",
    "        team2_info = self.output_team2_info(embs)\n",
    "        return team1_win, team1_info, team2_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7ef421",
   "metadata": {
    "papermill": {
     "duration": 0.011042,
     "end_time": "2022-04-05T13:07:24.154995",
     "exception": false,
     "start_time": "2022-04-05T13:07:24.143953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Read file, Define DataManager and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4f2eb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T13:07:24.183832Z",
     "iopub.status.busy": "2022-04-05T13:07:24.183227Z",
     "iopub.status.idle": "2022-04-05T13:07:25.074228Z",
     "shell.execute_reply": "2022-04-05T13:07:25.073548Z",
     "shell.execute_reply.started": "2022-04-05T12:49:29.798108Z"
    },
    "papermill": {
     "duration": 0.908102,
     "end_time": "2022-04-05T13:07:25.074379",
     "exception": false,
     "start_time": "2022-04-05T13:07:24.166277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df = get_df(SAMPLE_SUBMISSION_FILE)\n",
    "reg_df = get_df(REGULAR_FILE)\n",
    "nca_df = get_df(NCAA_FILE)\n",
    "\n",
    "dm = DataManager(reg_df, nca_df, sub_df, device)\n",
    "\n",
    "model = IterativeModel(\n",
    "    num_team = dm.num_team,\n",
    "    num_info = len(INFO_COLS),\n",
    "    team_emb_size = TEAM_EMB_SIZE,\n",
    "    model_emb_size = MODEL_HIDDEN_SIZE\n",
    ").to(device)\n",
    "\n",
    "bce = nn.BCELoss()\n",
    "mse = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23461404",
   "metadata": {
    "papermill": {
     "duration": 0.011998,
     "end_time": "2022-04-05T13:07:25.099560",
     "exception": false,
     "start_time": "2022-04-05T13:07:25.087562",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train, Valid and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e4c292c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T13:07:25.137357Z",
     "iopub.status.busy": "2022-04-05T13:07:25.136248Z",
     "iopub.status.idle": "2022-04-05T13:07:41.488183Z",
     "shell.execute_reply": "2022-04-05T13:07:41.488669Z",
     "shell.execute_reply.started": "2022-04-05T12:49:30.327538Z"
    },
    "papermill": {
     "duration": 16.377663,
     "end_time": "2022-04-05T13:07:41.488836",
     "exception": false,
     "start_time": "2022-04-05T13:07:25.111173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ======== Season 2003 ======== \n",
      "Train Season: 2003, bce: 0.7017, mse: 0.0076\n",
      "Valid Season: 2003, bce: 0.7222, mse: 0.0066\n",
      " ======== Season 2004 ======== \n",
      "Train Season: 2004, bce: 0.6760, mse: 0.0063\n",
      "Valid Season: 2004, bce: 0.6775, mse: 0.0060\n",
      " ======== Season 2005 ======== \n",
      "Train Season: 2005, bce: 0.6603, mse: 0.0059\n",
      "Valid Season: 2005, bce: 0.6008, mse: 0.0057\n",
      " ======== Season 2006 ======== \n",
      "Train Season: 2006, bce: 0.6397, mse: 0.0059\n",
      "Valid Season: 2006, bce: 0.6550, mse: 0.0061\n",
      " ======== Season 2007 ======== \n",
      "Train Season: 2007, bce: 0.6284, mse: 0.0059\n",
      "Valid Season: 2007, bce: 0.6286, mse: 0.0056\n",
      " ======== Season 2008 ======== \n",
      "Train Season: 2008, bce: 0.6303, mse: 0.0059\n",
      "Valid Season: 2008, bce: 0.5298, mse: 0.0070\n",
      " ======== Season 2009 ======== \n",
      "Train Season: 2009, bce: 0.6189, mse: 0.0056\n",
      "Valid Season: 2009, bce: 0.5624, mse: 0.0064\n",
      " ======== Season 2010 ======== \n",
      "Train Season: 2010, bce: 0.6022, mse: 0.0056\n",
      "Valid Season: 2010, bce: 0.5813, mse: 0.0060\n",
      " ======== Season 2011 ======== \n",
      "Train Season: 2011, bce: 0.5842, mse: 0.0054\n",
      "Valid Season: 2011, bce: 0.6278, mse: 0.0049\n",
      " ======== Season 2012 ======== \n",
      "Train Season: 2012, bce: 0.5909, mse: 0.0054\n",
      "Valid Season: 2012, bce: 0.6415, mse: 0.0044\n",
      " ======== Season 2013 ======== \n",
      "Train Season: 2013, bce: 0.5887, mse: 0.0054\n",
      "Valid Season: 2013, bce: 0.5702, mse: 0.0049\n",
      " ======== Season 2014 ======== \n",
      "Train Season: 2014, bce: 0.5818, mse: 0.0054\n",
      "Valid Season: 2014, bce: 0.5899, mse: 0.0053\n",
      " ======== Season 2015 ======== \n",
      "Train Season: 2015, bce: 0.6004, mse: 0.0053\n",
      "Valid Season: 2015, bce: 0.4765, mse: 0.0047\n",
      " ======== Season 2016 ======== \n",
      "Train Season: 2016, bce: 0.5891, mse: 0.0053\n",
      "Valid Season: 2016, bce: 0.5208, mse: 0.0049\n",
      " ======== Season 2017 ======== \n",
      "Train Season: 2017, bce: 0.5867, mse: 0.0054\n",
      "Valid Season: 2017, bce: 0.5301, mse: 0.0047\n",
      " ======== Season 2018 ======== \n",
      "Train Season: 2018, bce: 0.5995, mse: 0.0053\n",
      "Valid Season: 2018, bce: 0.5818, mse: 0.0064\n",
      " ======== Season 2019 ======== \n",
      "Train Season: 2019, bce: 0.6017, mse: 0.0053\n",
      "Valid Season: 2019, bce: 0.5388, mse: 0.0050\n",
      " ======== Season 2021 ======== \n",
      "Train Season: 2021, bce: 0.6184, mse: 0.0053\n",
      "Valid Season: 2021, bce: 0.6572, mse: 0.0061\n",
      " ======== Season 2022 ======== \n",
      "Train Season: 2022, bce: 0.5889, mse: 0.0051\n",
      "Run Testing\n",
      "\n",
      "mean bce: 0.589875\n",
      "mean mse: 0.005585\n"
     ]
    }
   ],
   "source": [
    "test_pred = []\n",
    "valid_bce = []\n",
    "valid_mse = []\n",
    "\n",
    "for season in SEASONS:\n",
    "    print(f' ======== Season {season} ======== ')\n",
    "\n",
    "    # get data of given season\n",
    "    train_data, valid_data, test_data = dm.get_train_data(season=season)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # train\n",
    "    model.train()\n",
    "    mt = MetricTracker()\n",
    "    for data in train_data:\n",
    "        # pred\n",
    "        team1_win_pred, team1_pred, team2_pred = model(data.team1_ids, data.team2_ids)\n",
    "\n",
    "        # compute loss\n",
    "        bce_loss = bce(team1_win_pred, data.team1_win)\n",
    "        team1_info_loss = mse(team1_pred, data.team1_data)\n",
    "        team2_info_loss = mse(team2_pred, data.team2_data)\n",
    "        mse_loss = torch.mean((team1_info_loss + team2_info_loss) / 2 * INFO_COLS_LOSS_WEIGHT)\n",
    "        loss = TEAM1_WIN_LOSS_WEIGHT * bce_loss + INFO_LOSS_WEIGHT * mse_loss\n",
    "        \n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # update metric\n",
    "        mt.update(\n",
    "            count=len(team1_pred),\n",
    "            bce=bce_loss.item(), \n",
    "            mse=mse_loss.item()\n",
    "        )\n",
    "    print(f\"Train Season: {season}, {mt}\")\n",
    "\n",
    "    # valid\n",
    "    if valid_data: \n",
    "        model.eval()\n",
    "        mt = MetricTracker()\n",
    "        for data in valid_data:\n",
    "            # pred\n",
    "            team1_win_pred, team1_pred, team2_pred = model(data.team1_ids, data.team2_ids)\n",
    "\n",
    "            # compute loss\n",
    "            bce_loss = bce(team1_win_pred, data.team1_win)\n",
    "            team1_info_loss = mse(team1_pred, data.team1_data)\n",
    "            team2_info_loss = mse(team2_pred, data.team2_data)\n",
    "            mse_loss = torch.mean((team1_info_loss + team2_info_loss) / 2 * INFO_COLS_LOSS_WEIGHT)\n",
    "\n",
    "            # update metric\n",
    "            mt.update(\n",
    "                count=len(team1_pred),\n",
    "                bce=bce_loss.item(), \n",
    "                mse=mse_loss.item()\n",
    "            )\n",
    "\n",
    "            valid_bce.append(mt.bce / mt.count)\n",
    "            valid_mse.append(mt.mse / mt.count)\n",
    "            \n",
    "        print(f\"Valid Season: {season}, {mt}\")\n",
    "\n",
    "    if test_data:\n",
    "        # test\n",
    "        model.eval()\n",
    "        team1_ids, team2_ids = test_data\n",
    "        team1_win_pred, _, _ = model(team1_ids, team2_ids)\n",
    "        test_pred += team1_win_pred.tolist()\n",
    "        print(\"Run Testing\")\n",
    "\n",
    "print(f\"\\nmean bce: {np.mean(valid_bce):4f}\")\n",
    "print(f\"mean mse: {np.mean(valid_mse):4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fcb1f29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T13:07:41.531233Z",
     "iopub.status.busy": "2022-04-05T13:07:41.530627Z",
     "iopub.status.idle": "2022-04-05T13:07:41.542131Z",
     "shell.execute_reply": "2022-04-05T13:07:41.541623Z",
     "shell.execute_reply.started": "2022-04-05T12:49:48.670578Z"
    },
    "papermill": {
     "duration": 0.035606,
     "end_time": "2022-04-05T13:07:41.542297",
     "exception": false,
     "start_time": "2022-04-05T13:07:41.506691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df['Pred'] = test_pred\n",
    "sub_df.to_csv(f'sub_{GENDER}.csv', index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30.520308,
   "end_time": "2022-04-05T13:07:42.369620",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-05T13:07:11.849312",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
